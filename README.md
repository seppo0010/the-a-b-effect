# Objecting to experiments that compare two unobjectionable policies or treatments

## Pasos a seguir

Según el maestro Palamago https://twitter.com/palamago/status/1053357438982856705

1. Elegir el tema. 

2. Mapa. 
   Poner en una sola hoja todos los temas que se querían tocar en la charla y relacionarlos
   en una especie de mapa conceptual.

3. Temas & orden.
   Mirando el mapa, separarlo en tópicos y subtópicos (no estoy hablando de slides aún) y
   darles un orden lógico que conecte las distintas partes.

4. Guión.
   Pensando en los post-it y sus temas escribí el guión de corrido. Una narrativa que toca
   todos los temas y los va hilando. 
   Profundizo cosas y aprendo nuevas para complementar esta columna vertebral.
   Acá se nota cuando hay cosas que no tienen sentido o están forzadas. 
   Se limpia y se reordena hasta que la narrativa tenga sentido leyéndola de corrido.
   Esto es la charla.

5. Presentación.
   Ahora si armo las slides. Con poco texto.  Que ilustren, que sea una guía.
   Busco videos de fondo que puedan motivar, imágenes que impacten.
   Poco para leer, mucho para mirar y escuchar.
   La charla está en lo que se escucha. La presentación como soporte visual.

6. Practicar

## Tema

Objeción a la experimentación aún cuando ninguna de las opciones es objetable.

## Mapa

* A/B tests son criticados por motivos éticos pero tanto la implementación de A como la de B no
  es considerada objetable.
  > when in fact the rest of the world outside the experiment is often just the A condition of
  > an A/B test that was never conducted

* Belmort Report

  Estados Unidos, Department of Health, Education, and Welfare, 1979.

  Ethical Principles and Guidelines for the Protection of Human Subjects of Research

  A special problem of consent arises where informing subjects of some pertinent aspect of the
  research is likely to impair the validity of the research. In many cases, it is sufficient to
  indicate to subjects that they are being invited to participate in research of which some
  features will not be revealed until the research is concluded. In all cases of research involving
  incomplete disclosure, such research is justified only if it is clear that (1) incomplete
  disclosure is truly necessary to accomplish the goals of the research, (2) there are no
  undisclosed risks to subjects that are more than minimal, and (3) there is an adequate plan for
  debriefing subjects, when appropriate, and for dissemination of research results to them.
  Information about risks should never be withheld for the purpose of eliciting the cooperation of
  subjects, and truthful answers should always be given to direct questions about the research.
  Care should be taken to distinguish cases in which disclosure would destroy or invalidate the
  research from cases in which disclosure would simply inconvenience the investigator. 

* What happens when Facebook doesn’t tell you a friend has died?

  Before his death, the friend posted a status update about being in the hospital. But Vainio
  hadn’t seen the message, despite habitually reading every post on her feed in chronological
  order. Mutual friends didn’t remember seeing the post, either.

* Existen experimentos objetables si una de las opciones ya se sabe que es peor o si los efectos
  colaterales de una opción pueden ser preferibles, por ejemplo, pero ¿por qué objetaríamos a
  experimentos donde las dos opciones donde, a priori, una no es mejor que la otra.

  Ejemplos:

  * Pearson Education y su frase motivacional

  * OkCupid midiendo la eficacia de su algoritmo de matches

    * “OkCupid simply lied, falsifying their results and intentionally mismatching people.
    This manipulation invariably lead to countless terrible dates, wasted money, increased
    frustration and quite likely questions as to why these users could not find the love they
    were seeking.”

    * But that conclusion only follows if OkCupid already knew, prior to the  experiment, that
    its computed compatibility probabilities were  accurate

  * Facebook midiendo el impacto de los posts que le mostraba a sus usuarios en su felicidad.

      * <2007 Facebook cambiaba configuración de newsfeed a mano ("más fotos, menos plataforma").
         En 2007 crearon EdgeRank que medía afinidad (entre los amigos), peso (likes e interacciones)
         y decaimiento (en tiempo).
         En 2010 pasaron a usar ML.

      * Los posts son mayormente positivos.

      * By 2011, twenty-­‐seven percent of all time spent on Facebook was spent on News Feed. [...]
      What are the effects [...]? Academic studies have suggested two contradictory hypothes about the
      risks of Facebook use to its 1.35 billion users: that exposure to friends’ positive posts is
      psychologically risky (through a social comparison mechanism) and that exposure to negative posts
      is psychologically risky (through an emotional contagion mechanism). 10  But these contradictory
      studies were mostly small and observational.

      *  Like much behavioral research, if the Facebook experiment had been conducted with users who
      had consented to participate after being fully informed about what behaviors the researchers were
      looking for and why and how they intended to elicit those responses, the results would have been
      badly biased, perhaps to the point of being deemed useless by the scientific community. Subjects’
      behavior would almost certainly have been altered by this knowledge (and in any case, this
      biasing effect could not be ruled out without comparing the results of two studies—one with fully
      informed consent and one, like the actual experiment, without it). Moreover, although requiring
      informed consent always poses some risk of rendering the results less generalizable through
      selection bias, in this case it is especially likely that users who opted into the fully
      disclosed study would have been different from those who opted out, in ways that would have
      mattered for producing results that generalize to Facebook’s 1.35 billion users.

      * Facebook experiment could have been conducted with incompletely informed consent (rather than
      no informed consent at all) without significantly biasing the results is a closer question,
      scientifically speaking. Users might have been invited to participate in a study and told that
      the algorithm that curates their News Feed would be adjusted (in unspecified ways) for one week.
      Users who opt in might still be materially different from those who opt out, and those who agree
      to participate might behave differently in response to the intervention than they would have had
      they not been primed by the consent process to pay attention to the content of their News Feed.

      * In the Facebook case, the alleged risk would have materialized during the week-long
      intervention as a result of increased exposure to positive or negative words. Neither
      debriefing nor the opportunity to withdraw their data from the analysis of the effects of
      that intervention can erase any harm that occurred or restore subjects’ opportunity to
      exercise their autonomy by agreeing or refusing to assume the risk of that harm.

  * Tratamientos para bebés prematuros.

  * Flexibilidad de horarios de residencia afectando los resultados de los pacientes.

* A veces los resultados no son los que uno hubiese anticipado, como los de Pearson Education
  que los estudiantes que recibieron mensajes alentadores intentaron menos problemas.

* Estudio 1: badge vs poster vs badge/poster. Badge/poster fue considerado más inapropiado.

* Explicaciones posibles:

  1. Una opción parece superior a la otra. Estudio 4 lo cambia a dos drogas diferentes sin detalles
     y el efecto se mantiene.

  2. Aversión a la aleatoriedad. Estudio 5 cambia la aleatoriedad diciendo que cada médico tiene
     una preferencia y los pacientes no pueden elegir el médico. El efecto subsiste pero es menor.

  3. Falta de consentimiento. Sin embargo no objetan a que no se hacía nada, ni a ninguna de las
     alternativas de ser universal.

  4. "mad scientist" trope. Incluso siendo explícita la motivación el resultado prevalece.

  5. Ilusión de conocimento. Los participantes pueden tener la ilusión de que los profesionales
     deberían saber la respuesta. Esto conlleva a que A/B testing sea menos aceptable y que A o B
     sean más. El estudio 4 demuestra que esto no explica toda la diferencia.

  6. Aversión a la experimentación. La idea de un experimento lleva sentimientos negativos.

  7. El nivel de educación. Sin embargo el efecto se mantiene en el Estudio 6 realizado sólo con
     profesionales del área.

  8. ???

* Consecuencias

  * Políticos pueden ser más reacios a experimentar por caer en este efecto o por creer que sus
    constituyentes caerían en él. Menos experimentos significa menos conocimiento.

  * Personas aversas a la experimentación pueden sesgar las muestras de los experimentos declinando
    a participar.

## Temas y orden

Qué es A/B testing.

Replicar Estudio 1 con los participantes.

Limitaciones de A/B testing. Consentimiento. Belmort Report.

Historia de Timeline de Facebook. Historia de terror de amigo hospitalizado. A/B testing de
sentimientos. Pearson Education. Experimento de OkCupid con matches. Tratamiento de bebés, horarios
flexibles de residentes. ¿Están bien?

Si A y B son alternativas aceptables, ¿Por qué A/B testing no? Estudio 1.

Explicaciones posibles.

Consecuencias posibles.

## Guión

A/B testing, o randomized controlled trial (prueba controlada aleatorisada) es una forma de evaluar
distinas opciones para ver cuál es más efectiva. Se usa mucho en medicina para comparar tratamientos
contra no tratamientos (o placebos) o entre ellos, pero también se usa bastante en las empresas
para evaluar distintas opciones de acuerdo al comportamiento de los usuarios.

A/B testing consiste en elegir opciones a evaluar (dos o más) y dividir aleatoriamente a la
población en la misma cantidad de grupos, asignarle a cada uno una opción y ver los resultados.
Por ejemplo si tenemos una nueva opción para el botón de comprar en nuestro sitio le podemos mostrar
a una porción aleatoria de nuestros usuarios la nueva versión y ver si eso afecta las ventas de
alguna forma.

Ahora bien, no para todos los problemas se puede estudiar de esta forma. por ejemplo si queremos
ver la reacción de personas a un estímulo con preguntarles no alcanza porque pueden mentir o
estimar mal su comportamiento. Ahí la única posibilidad es exponer a las personas a una situación
y ver su reacción. El problema que surge ahí es el consentimiento y evitarles daños a los
participantes.

En Estados Unidos esto se rige por el Belmont Report: Ethical Principles and Guidelines for the
Protection of Human Subjects of Research, Report of the National Commission for the Protection of
Human Subjects of Biomedical and Behavioral Research. Sobre este caso lo que propone es indicarle
a los sujetos que están siendo invitados a participar de una investigación pero que los detalles
no se les van a revelar hasta que concluya. Para poder hacer esto es requisito que sea necesario
para el experimento, que los riesgos para los individuos no sea más que mínimos y que haya un plan
para informar a los sujetos cuando el experimento haya concluido. Cuando esto pasa es necesario
no ocultar riesgos y responder cualquier pregunta que hagan las personas.

Ahora veamos un caso de experimentación sobre el comportamiento de personas que se hizo de forma
masiva. Facebook quiso medir el impacto de los posts que ven los usuarios sobre su estado de ánimo.

Inicialmente el _News Feed_ tenía una configuración manual. Después Facebook desarrolló _EdgeRank_
que elegía historias basadas en afinidad, importancia y decaímiento, y a partir de 2010 el orden
lo establece con Machine Learning viendo muchas cosas.

La pregunta que querían responder era si el estado de ánimo se contagia, es decir si ver mensajes
felices pone feliz al usuario, o si por el contrario hay una idea de competencia constante donde
ver mensajes felices pone a la persona triste por compararse con otras.

Hasta ese momento Facebook optimizaba el _News Feed_ de acuerdo a sus objetivos: qué es lo que creen
mejor para sus usuarios, qué es lo mejor para ganar plata. Al hacer un experimento sobre el estado
de ánimo de sus usuarios la meta es otra, pero no tan diferente, porque sin este experimento no
saben si lo que están haciendo de buena fe es en realidad perjudicial para sus usuarios.

Algo parecido hizo OkCupid con sus usuarios. OkCupid es un sitio/app de citas que le hace a sus
usuarios preguntas sobre preferencias de distinto tipo (político, social, moral, sexual), qué
respuestas desean que la otra persona responda y cuánto le importa, y en base a eso, y otras cosas
da un puntaje. Ahora bien, ¿Cómo evaluás el éxito del puntaje? Si de alguna forma podés ver si
fueron un buen _match_, ¿cómo sabés que no fue porque le diste un puntaje alto, o hasta qué punto
influye? Entonces para medir esto OkCupid hizo un experimento durante un período de tiempo
mostrando porcentajes distintos a sus usuarios de los que su algoritmo decía y ver si los valores
que mostraban tenían el significado que creían.

Si aceptamos que Facebook nos cure el News Feed como cree conveniente, y aceptamos que OkCupid nos
dé un valor de coincidencia con otra persona, ¿por qué consideramos que cambios en ello para
entender mejor sus efectos son problemáticos? O sea, si en un experimento tanto A como B nos
parecen alternativas razonables, ¿por qué nos puede incomodar un experimento que compare A y B?

Ésa es la pregunta a la que el paper en cuestión intenta buscar una respuesta. Primero establece
que ocurre este efecto, para eso hace un A/B testing sobre A/B testing. El experimento que hacen
es contarle a los participantes del experimento que para evitar infecciones al hacer un
procedimiento médico el director de un hospital piensa que una checklist puede ayudar a los doctores
por lo que la imprime en el reverso de la credencial en un caso, como poster en la pared de la sala
alternativamente o una tercera opción que es hacer un A/B testing entre las dos opciones, ver
cuál da mejores resultados y quedarse con esa. Después le preguntan qué tan apropiada le parece
la decisión del director y por qué. Consistentemente se ve que el A/B test parece más inapropiado
para más gente que tanto A como B.

Ahora, ¿por qué es esto? A los investigadores le surgieron distintas hipótesis, en parte inspirados
por los comentarios del experimento inicial, y en base a eso diseñaron distintos experimentos para
evaluar el efecto de cada una.

La primera hipótesis fue que quizás había gente que consideraba una de las dos opciones superior
a la otra y por eso le parecía innecesario el experimento y que al hacerlo exponía peligros
innecesarios a los pacientes, por lo que hicieron una segunda prueba donde comparaban una droga A
con una droga B de la que no tenían más información que las distinga, y se vuelve a dar una
preferencia contra la experimentación.
